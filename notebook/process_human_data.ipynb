{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "f_raw = \"../data/human_data_raw.jsonl\"\n",
    "\n",
    "with open(f_raw) as fin:\n",
    "    data = [json.loads(line) for line in fin]\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer never answers the question and focuses on a different conclusion. The hypothesis in the context says \"the rabbit is big\" but the answer is unknown because there is not enough information to determine that.\n",
      " \n",
      "The steps given do not give the right answer, The answer divided the The blue cars speed with the Green cars speed instead of multiply to get the actual speed. From the context The blue car travels at a speed of 80m/h so the green travels at 80*8=640m/h. the the  red one is twice as green so it will be 640*2=1280m/h.\n",
      " \n",
      "In their answer, the answer states that \"they sold 6*3=18 shoes\" but this number is actually the revenue from the shoes, not the number of shoes. The answer then proceeds to multiply this by 3 again which yields the whole calculation incorrect. The correct process should be to multiply the pairs of shoes by 3 to get $18, then multiply 18 shirts by 2 to get $36, and sum this to get the total of $54. If they divide their total earning equally, each will get $27 which is the right answer.\n",
      " \n",
      "The answerâ€™s answer is incorrect. 3 kilos is the amount of sugar that fell to the ground. The context asks to find the amount of sugar that remains. The correct answer would subtract 3 kilos from 24 kilos. Therefore, 21 kilos is the correct answer.\n",
      " \n",
      "The answer cannot answer the question because the context does not provide enough information to come to a justifiable conclusion.\n",
      "The rule does not state is the cat can see the cow.  \n",
      " \n",
      "The answer never answers question. It says \"Therefore, while it is possible that the individual will be happy after finding out they don't have cancer, it is also possible that they will be upset or unsettled by the experience\". The correct answer is happiness. \n",
      " \n",
      "The answer only answered  how much geckos Brandon sold in the previous year but the question was how much he sold altogether so the answer should be what he sold this year plus what he sold the previous year.\n",
      " \n",
      "1317\n",
      "{2: 86, 1: 1230, 3: 1}\n",
      "{'Coherence and Deduction': 875, 'Commonsense': 226, 'Arithmetic': 161, 'Veracity': 143}\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "err_cnt_dist = dict()\n",
    "err_type_dist = dict()\n",
    "for idx,line in enumerate(data):\n",
    "    # print(idx)\n",
    "    \n",
    "    flag = False\n",
    "    if \"CLASSIFICATION_JOB_2\" in line[\"latestLabel\"][\"jsonResponse\"]:\n",
    "        flags = line[\"latestLabel\"][\"jsonResponse\"][\"CLASSIFICATION_JOB_2\"][\"categories\"]\n",
    "        for i in range(len(flags)):\n",
    "            if line[\"latestLabel\"][\"jsonResponse\"][\"CLASSIFICATION_JOB_2\"][\"categories\"][i][\"name\"] == \"ERRORS_IN_THE_CORRECT_OUTPUT\":\n",
    "                flag = True\n",
    "            elif line[\"latestLabel\"][\"jsonResponse\"][\"CLASSIFICATION_JOB_2\"][\"categories\"][i][\"name\"] == \"THE_CONTEXT_IS_VERY_COMPLEX_IM_NOT_SURE_OF_MY_ANSWER\":\n",
    "                flag = True\n",
    "    if flag:\n",
    "        continue\n",
    "\n",
    "    labels = line[\"latestLabel\"][\"jsonResponse\"][\"CLASSIFICATION_JOB_0\"][\"categories\"]\n",
    "    feedback = []\n",
    "    error_types = []\n",
    "    for label in labels:\n",
    "        feedback.extend([i[\"text\"] for i in label[\"children\"].values()])\n",
    "        error_types.append(label[\"categoryName\"])\n",
    "        \n",
    "    # priorities\n",
    "    priorities = ['Coherence and Deduction', 'Veracity', 'Arithmetic', 'Commonsense'] #'Consistency with Context', 'Redundancy']\n",
    "    \n",
    "    if len(feedback) > 1:\n",
    "        new_feedback = []\n",
    "        new_error_type = []\n",
    "        \n",
    "        for priority in priorities:\n",
    "            for type_idx in range(len(feedback)):\n",
    "                if error_types[type_idx] == priority:\n",
    "                    new_error_type.append(priority)\n",
    "                    new_feedback.append(feedback[type_idx])\n",
    "        \n",
    "        feedback = new_feedback\n",
    "        error_types = new_error_type\n",
    "        \n",
    "    if len(feedback) < 1: continue\n",
    "                    \n",
    "    \n",
    "    # remove candidate\n",
    "    for item_id in range(len(feedback)):\n",
    "        if \"victory is an election result in which the victorious candidate\" in feedback[item_id]: \n",
    "            feedback[item_id] = feedback[item_id].replace(\"Candidates\", \"The answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"the candidate output\", \"the answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"the candidate output's answer\", \"the answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"the candidate's answer\", \"the answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"The candidate output\", \"The answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"The candidate output'answer\", \"The answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"The candidate'answer\", \"The answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"the candidate had the answer\", \"the answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"the candidates answer\", \"the answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"the candidate\", \"the answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"the candidate does not answer the question\", \"this does not answer the question\")\n",
    "        \n",
    "        feedback[item_id] = feedback[item_id].replace(\"The candidates\", \"The answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"The candidate\", \"The answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"The candidate's answer\", \"The answer\")\n",
    "        \n",
    "        feedback[item_id] = feedback[item_id].replace(\"The output candidate\", \"The answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"the output candidate\", \"the answer\")\n",
    "        \n",
    "        feedback[item_id] = feedback[item_id].replace(\"candidate's answer\", \"the answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"the candidate output\", \"the answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"candidate output\", \"the answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"Candidate output\", \"The answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"Candidate Output\", \"The answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"candidate answers\", \"it answers\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"Th candidate\", \"The answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"Output Candidate\", \"The answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"Output candidate\", \"The answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"Candidate\", \"The answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"Candidates\", \"The answer\")\n",
    "        \n",
    "        feedback[item_id] = feedback[item_id].replace(\"candidate\", \"the answer\")\n",
    "        \n",
    "        \n",
    "        feedback[item_id] = feedback[item_id].replace(\"The answer answers \", \"The answer says \")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"the answer answers \", \"the answer says \")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"The answer answered \", \"The answer sayed \")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"the answer answered \", \"the answer sayed \")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"The answer answer\", \"The answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"The answer in the answer\", \"The answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"the answers' answer\", \"the answer\")\n",
    "        feedback[item_id] = feedback[item_id].replace(\"The answer's answer\", \"The answer\")\n",
    "        \n",
    "        \n",
    "        answer_loc_1 = feedback[item_id].find(\"answer\")\n",
    "        answer_loc_2 = feedback[item_id][answer_loc_1+5:].find(\"answer\")\n",
    "        if answer_loc_2 > -1 and answer_loc_2 < 10:\n",
    "            print(feedback[item_id])\n",
    "            print(\" \")\n",
    "    \n",
    "    my_key = \"candidate\"\n",
    "    for item in feedback:\n",
    "        loc = -1\n",
    "        if my_key in item:\n",
    "            loc = item.find(my_key)\n",
    "        \n",
    "        if loc > -1:\n",
    "            print(item[loc:loc+155])\n",
    "    \n",
    "    \n",
    "        \n",
    "    if len(feedback) in err_cnt_dist:\n",
    "        err_cnt_dist[len(feedback)] += 1\n",
    "    else:\n",
    "        err_cnt_dist[len(feedback)] = 1\n",
    "        \n",
    "    for err_type in error_types:\n",
    "        if err_type in err_type_dist:\n",
    "            err_type_dist[err_type] += 1\n",
    "        else:\n",
    "            err_type_dist[err_type] = 1\n",
    "        \n",
    "    question = line[\"metadata\"][\"context\"]\n",
    "    answer = line[\"metadata\"][\"output_candidate\"]\n",
    "    \n",
    "    critique = \" \".join(feedback)\n",
    "    if \"correct output\" in critique or \"Correct output\" in critique or \"Correct Output\" in critique:\n",
    "#         print(\"prompt_id:\", line[\"metadata\"][\"prompt_id\"])\n",
    "        continue\n",
    "    \n",
    "    outputs.append({\"question\": question,\n",
    "                  \"answer\": answer,\n",
    "                  \"feedback\": feedback,\n",
    "                  \"error_types\": error_types})\n",
    "print(len(outputs))\n",
    "print(err_cnt_dist)\n",
    "print(err_type_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firstly, The math is off in the previous to last sentence, since the ages of the children should be subtracted, not summed. 15 - 1 - 4 -2 = 8 is the right answer. Secondly, \"So the fourth child is 15 + 1 + 4 + 2 = 22 years old. The answer is 22.\" The fourth born child cannot be older than the first born child.  \n",
      "['Coherence and Deduction', 'Commonsense']\n",
      "\n",
      "Blowing on the open end won't help. After tearing a hole at the end of the paper, the rest can be pulled from the other side to release the straw.\n",
      "['Commonsense']\n",
      "\n",
      "After giving an explanation, the answer does not provide an answer.\n",
      "['Coherence and Deduction']\n",
      "\n",
      "The answer doesn't answer the question directly and there are missing steps. The hypothesis is not correct because if something eats the cat and it does not visit the cat then the cat needs the cow. The answer doesn't list any of the correct steps to get to the cat needing the cow.\n",
      "['Coherence and Deduction']\n",
      "\n",
      "2nd statement that Dave is not furry by the answer is incorrect. We do know that Dave is furry because Dave is big (3rd sentence of context) and big people are furry (11th sentence). If someone is furry, then they are rough. Dave is rough. Rough people are nice. Dave is nice. All nice people are young. Dave is young. If someone is young then they are smart thus Dave is smart.  \n",
      "['Veracity']\n",
      "\n",
      "The answer uses incorrect logical steps which lead to a wrong conclusion. The answer misunderstands that if they both bought the same number of bananas, they are irrelevant in this particular equation and this allows us to calculate the price of a dozen apples, which is $2. If Arnold paid $5 in total, and the cost of apples is $2, then the cost of bananas is $3 per branch.\n",
      "['Coherence and Deduction']\n",
      "\n",
      "The answer is missing various steps in its calculation and arrives at the wrong answer. The correct approach is to calculate how many students have which daily allowance, and then we get that 40 students who received 6 per day => 40*6=$240 and 20 students got 20*4=$80, so the sum and correct answer is $320.\n",
      "['Coherence and Deduction']\n",
      "\n",
      "The answer performs a wrong step 3000*4 instead of 3000/3*4=4000. This leads the answer to a wrong answer.\n",
      "['Coherence and Deduction']\n",
      "\n",
      "The answer makes reference to  Commodore 64, an old computer from 1982. This doesn't make sense as this computer no longer is relevant and wasn't used for games. The correct answer would be that there is a game called \"Superman\" on Nintendo 64.\n",
      "['Veracity']\n",
      "\n",
      "The answer says that the tenants are best described as senior citizens. Given the context, it is more probable that the tenants were college students than senior citizens (e.g. because it is stated in the context that this was their first place)\n",
      "['Commonsense']\n",
      "\n",
      "The output has bad logic when it says that the person should \"immediately start scrubbing.\" That is not the right way to get the stain out. The right answer is to allow the spray to sit for ten minutes before starting to scrub.\n",
      "['Coherence and Deduction']\n",
      "\n",
      "The narrator lists specs of the phone, and from their tone, it's very likely they have already used the phone.\n",
      "Therefore, the context is most likely a user review. Additionally, the answer needs to justify why this would be the correct answer.\n",
      "['Coherence and Deduction']\n",
      "\n",
      "The context says \"I don't fool with weighing anything, checking food stats (calories, fat, carbs, etc)\" so we can assume that given the context the they won't count anything. The answer of \"I will eat second helpings\" doesn't make sense given the context. The correct answer to \"what may happen as I eat my lunch during my lunch break?\" is I won't count calories. \n",
      "['Coherence and Deduction']\n",
      "\n",
      "The answer says \"the best place to find many books is a university\" which is incorrect. The question asks where you can find many stores with books, therefore the correct answer would be a large city.\n",
      "['Coherence and Deduction']\n",
      "\n",
      "The answer is right until its fifth sentence. Then he is missing a step also forgets to add the previous 160 to the 460. Therefore, the correct approach should be 460+160=620; then after fixing his car he was left with 620-340=280, and he thus needs 600-280=320. Given that he gets 20 per hour, he will need to work another 320/20=16 hours\n",
      "['Coherence and Deduction']\n",
      "\n",
      "To see competency in someone, you must either have seen them doing the exercise before or see visible ability to do it successful.\n",
      "Since the trainer has a disability it would be difficult to judge their competency at face value. Potential is judging someone's ability to master something after a period of time =.\n",
      "['Coherence and Deduction']\n",
      "\n",
      "The context states that the narrator opened the bottle and had some chocolate - emphasis on 'some'\n",
      "The answer implies that the narrator drank the entire bottle.\n",
      "the right answer would have been that the narrator was excited and very exuberant. \n",
      "['Coherence and Deduction']\n",
      "\n",
      "An artist is an individual who participates in creative arts such as painting. \n",
      "From the options provided, the only way an artist would create a fox is by painting one on a canvas.   \n",
      "['Coherence and Deduction']\n",
      "\n",
      "Bad reasoning appears in the second paragraph of the output. It arrives at an answer of 8 when the right answer is 12. Without the laptop and work papers the briefcase is 16 pounds. Taking away the 4 that the empty briefcase weighs results in a preliminary sum of 12. That number is then divided by 6 to arrive at the weight of papers: 2 pounds. Taking 2 away from 12 results in a final answer of 10 pounds for the weight of the laptop.\n",
      "['Coherence and Deduction']\n",
      "\n",
      "1317\n"
     ]
    }
   ],
   "source": [
    "version = 0\n",
    "\n",
    "processed_outputs = []\n",
    "err_type_dist = dict()\n",
    "\n",
    "bad_count_redundancy = 10\n",
    "bad_count_consistent = 10\n",
    "\n",
    "for idx, output in enumerate(outputs):\n",
    "    \n",
    "    if len(output[\"feedback\"]) == 1:\n",
    "        if output[\"error_types\"][0] == \"No error\":\n",
    "            critique = output[\"feedback\"][0]\n",
    "        elif \" correct\" in output[\"feedback\"][0]:\n",
    "            critique = output[\"feedback\"][0]\n",
    "        elif output[\"error_types\"][0] in [\"Redundancy\", \"Consistency with Context\"]:\n",
    "            critique = output[\"feedback\"][0]\n",
    "        else:\n",
    "            critique = \"\" + output[\"feedback\"][0]\n",
    "            \n",
    "        if output[\"error_types\"][0] == \"Redundancy\":\n",
    "            if bad_count_redundancy > 0:\n",
    "                bad_count_redundancy -= 1\n",
    "            else:\n",
    "                continue\n",
    "        if output[\"error_types\"][0] == \"Consistency with Context\":\n",
    "            if bad_count_consistent > 0:\n",
    "                bad_count_consistent -= 1\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "    elif len(output[\"feedback\"]) == 2:\n",
    "        critique = \"Firstly, \" + output[\"feedback\"][0] + \" Secondly, \" + output[\"feedback\"][1]\n",
    "    elif len(output[\"feedback\"]) == 3:\n",
    "        critique = \"Firstly, \" + output[\"feedback\"][0] + \" Secondly, \" + output[\"feedback\"][1] + \\\n",
    "        \" Thirdly, \" + output[\"feedback\"][2]\n",
    "    \n",
    "    if \"in which the victorious candidate or party wins by an overwhelming margin. Therefore, the vote could not\" in critique: continue\n",
    "    \n",
    "    for err_type in output[\"error_types\"]:\n",
    "        if err_type in err_type_dist:\n",
    "            err_type_dist[err_type] += 1\n",
    "        else:\n",
    "            err_type_dist[err_type] = 1\n",
    "    \n",
    "#     if \"Veracity\" in output[\"error_types\"]:\n",
    "#         print(critique)\n",
    "    if idx % 70 == 0:\n",
    "        print(critique)\n",
    "        print(output[\"error_types\"])\n",
    "        print()\n",
    "    processed_outputs.append({\"id\":idx,\"question\":output[\"question\"],\"answer\":output[\"answer\"],\n",
    "                \"feedback\":critique,\"meta\":{\"domain\":\"human annotation\"}})\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print(len(processed_outputs))\n",
    "\n",
    "with open(f\"./v{version}.jsonl\", \"w\") as fout:\n",
    "    for output in processed_outputs:\n",
    "        fout.write(f\"{json.dumps(output)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Coherence and Deduction': 875, 'Commonsense': 226, 'Arithmetic': 161, 'Veracity': 143}\n"
     ]
    }
   ],
   "source": [
    "print(err_type_dist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
